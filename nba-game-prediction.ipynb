{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basketball Predictions\n",
    "In this workshop we're going to be training a machine learning algorithm for predicting basketball games based on previous basketball outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing, make sure to paste in the name of your specific S3 bucket that you created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'YOUR BUCKET NAME HERE'\n",
    "prefix =  bucket + '/DEMO-linear-dm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to input some packages for our script to work. These include things like pandas to more easily work with our data, and boto3 which is the python SDK for AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "import os                                         # For manipulating filepath names\n",
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "import sagemaker                                  # Amazon SageMaker's Python SDK provides many helper functions\n",
    "from sagemaker.predictor import csv_serializer    # Converts strings for HTTP POST requests on inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have a little bit of setup. We pull the current execution role which we will need later on. \n",
    "\n",
    "We also upload a local file to S3, and then pull it back down to work on it.\n",
    "In a production environment you wouldn't want to do this, but the code is here to show how to pull files from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "filename = 'basketball_predictions_112119.csv'\n",
    "boto3.client('s3').upload_file(filename, bucket, filename)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "object = s3.Object(bucket,'basketball_predictions_112119.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are loading the content from the csv file into a local data object using pandas. Then we're simply setting some display options so that we can view the data easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(object.get()['Body'])\n",
    "pd.set_option('display.max_columns', 5)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 15)       # Keep the output on one page\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to ensure the data is in the proper format that our training algorithm will expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = data.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are setting up our training X and Y values.\n",
    "\n",
    "The Y value will be the value to be predicted. In the case it is the point differential between the two teams. A positive point differential indicates a victory for team 1, whereas a negative point differential indicates a victory for team 2.\n",
    "\n",
    "The X value will be the data to be looked at when attempting to predict a winner. In this case it is all data except for the point differential itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = model_data['point_diff (N)']\n",
    "train_X = model_data.drop('point_diff (N)', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are importing the prebuilt sagemaker container that corresponds to the desired training algorithm. In this case it is the \"linear-learner\", which is a linear regression based algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are uploading our data set that we have created earlier to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, np.array(train_X).astype('float32'), np.array(train_y).astype('float32'))\n",
    "buf.seek(0)\n",
    "key = 'linear_train.data'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Your Model\n",
    "\n",
    "This is the code that actually trains the model. It allows us to specify the number and types of instances on which we will train. We will also define our hyperparamaters which are different variables that affect exactly how our model will be trained. This process can take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.m5.large',\n",
    "                                       output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                       sagemaker_session=sess)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim=4,\n",
    "                           mini_batch_size=1,\n",
    "                           predictor_type='regressor',\n",
    "                           epochs=5,\n",
    "                           loss='squared_loss')\n",
    "\n",
    "linear.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Your model\n",
    "\n",
    "Next we want to deploy our trained model so that we can query it for predictions. The following code takes the model we just trained and deploys it onto a t2.medium sized instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_predictor = linear.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Your Model\n",
    "\n",
    "Now the only thing left to do is test to see how your model performs. The following code queries the model we have created and deployed for a prediction based on the listed values.\n",
    "\n",
    "Feel free to alter these values and see how it affects the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_team_elo = 1471\n",
    "home_team_elo = 1328\n",
    "away_team_last10 = 0.5\n",
    "home_team_last10 = 0.2\n",
    "matchup = [away_team_elo,home_team_elo,away_team_last10,home_team_last10]\n",
    "\n",
    "\n",
    "endpoint_name = 'YOUR ENDPOINT HERE'\n",
    "predictor = sagemaker.predictor.RealTimePredictor(endpoint=endpoint_name,   #create predictor to send serialized data to sagemaker\n",
    "                                                serializer=sagemaker.predictor.csv_serializer,\n",
    "                                                content_type='text/csv')\n",
    "\n",
    "response = predictor.predict(matchup)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "Uncomment the following line (delete the # sign) in order to delete the endpoint you just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker.Session().delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
